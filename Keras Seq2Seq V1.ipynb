{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.424 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# standard\n",
    "from IPython import embed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# frameworks\n",
    "from frameworks.seq2seq_keras.models import AttentionSeq2Seq\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# custom\n",
    "from data_utils import get_train_data\n",
    "from word2vec import get_word_embedding\n",
    "from vocab import get_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_BATCH_SIZE = 64\n",
    "_VOCAB_SIZE = 6000\n",
    "_WORD_DIM = 128\n",
    "_MODEL_DEPTH = 4\n",
    "\n",
    "_INPUT_LENGTH = 25\n",
    "_OUTPUT_LENGTH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = AttentionSeq2Seq(input_length=_INPUT_LENGTH, \n",
    "                         input_dim=_WORD_DIM, \n",
    "                         hidden_dim=_WORD_DIM, \n",
    "                         output_length=_OUTPUT_LENGTH, \n",
    "                         output_dim=_WORD_DIM, \n",
    "                         depth=_MODEL_DEPTH)\n",
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_word_embedding(_WORD_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = get_train_data()\n",
    "_, ch2int = get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39956"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_to(lst, length, value):\n",
    "    for i in range(len(lst), length):\n",
    "        lst.append(value)\n",
    "    \n",
    "    return lst\n",
    "\n",
    "def clean_train_data(train_data):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for idx in xrange(len(train_data)):\n",
    "        line_number = idx % 4\n",
    "        \n",
    "        keyword = train_data[idx]['keyword']\n",
    "        current_sentence = train_data[idx]['sentence']\n",
    "        previous_sentences = ''.join([train_data[idx - i]['sentence'] for i in range(line_number, 0, -1)])\n",
    "        \n",
    "        X_entry = pad_to([[ch2int[ch]] for ch in (keyword + previous_sentences)], 25, [_VOCAB_SIZE - 1])\n",
    "        Y_entry = pad_to([[ch2int[ch]] for ch in current_sentence], 10, [_VOCAB_SIZE - 1])\n",
    "        \n",
    "        X_train.append(X_entry)\n",
    "        Y_train.append(Y_entry)\n",
    "        \n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = clean_train_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_embedded = [map(lambda x: embedding[x[0]], sample) for sample in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_embedded = [map(lambda x: embedding[x[0]], sample) for sample in Y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "39956/39956 [==============================] - 421s - loss: 0.4278   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f834e02d4d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_embedded, Y_train_embedded, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kw = u'山水'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kw_pad = [pad_to([[ch2int[ch]] for ch in kw], 25, [_VOCAB_SIZE - 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kw_embed = [map(lambda x: embedding[x[0]], sample) for sample in kw_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kw_embed_array = np.array(kw_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.08963315,  0.13422257, -0.24570994, ..., -0.14995289,\n",
       "          0.17542832,  0.13692029],\n",
       "        [-0.03718845,  0.30552149, -0.17106384, ..., -0.05145008,\n",
       "          0.19576812,  0.19635646],\n",
       "        [-0.08512392,  0.32059655, -0.13894799, ..., -0.04305276,\n",
       "          0.11034762,  0.05403135],\n",
       "        ..., \n",
       "        [ 0.82171226,  0.54636025,  0.8892892 , ..., -0.24688512,\n",
       "         -0.63101834,  0.0330935 ],\n",
       "        [ 0.84401846,  0.55392796,  0.92472196, ..., -0.2636658 ,\n",
       "         -0.64143229,  0.04308706],\n",
       "        [ 0.84558034,  0.54933226,  0.92686731, ..., -0.2670286 ,\n",
       "         -0.64220965,  0.04647564]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(kw_embed_array)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('data/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(pred[0])):\n",
    "    result.append(w2v_model.most_similar(positive=[pred[0][i]], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f62339b98eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print r[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8498039 ,  0.57556695,  0.92304476,  0.17803186,  0.04769286,\n",
       "        0.99453824, -0.82562774,  0.53770008,  0.73325625,  0.63910316,\n",
       "        0.39900191,  0.30091339, -0.03310214,  0.44781277, -0.71808411,\n",
       "       -0.07415888, -0.35380776, -0.38131324,  0.61963274, -0.91428909,\n",
       "       -0.27381443, -0.4955787 ,  0.20827111,  0.8872208 , -0.34586555,\n",
       "       -0.40137233, -0.85387734, -0.21692254, -0.04420312,  0.98681227,\n",
       "       -0.52111557, -0.56008486, -0.25052312, -0.28824903, -0.11583056,\n",
       "       -0.46158419,  0.82141598,  0.99022346,  0.00357126,  0.19400877,\n",
       "       -0.83994324,  0.14695139, -0.77157749, -0.91833494,  0.18459308,\n",
       "       -0.35598933, -0.45214338, -0.84804342,  0.71834489, -0.88759671,\n",
       "        0.2754031 , -0.45306053,  0.40938456, -0.9046748 , -0.15501666,\n",
       "       -0.11718657, -0.8087438 ,  0.05712781, -0.74951334,  0.54363642,\n",
       "       -0.15289607, -0.97428664,  0.65542609, -0.61612186, -0.9322828 ,\n",
       "        0.44299893,  0.4208495 , -0.85443294, -0.7864411 ,  0.60758014,\n",
       "        0.75646363,  0.68522318,  0.86649843, -0.03159488, -0.5698284 ,\n",
       "        0.07596831,  0.37773103, -0.8374563 ,  0.30470218, -0.34315225,\n",
       "       -0.99603866,  0.72274586, -0.08424495,  0.353141  , -0.69006159,\n",
       "        0.09112356,  0.38552215, -0.64422299,  0.8643223 , -0.27889414,\n",
       "       -0.52908717,  0.23784151,  0.60239361,  0.95516071,  0.57535124,\n",
       "       -0.5692499 ,  0.98829838, -0.8519413 , -0.20611532, -0.15758811,\n",
       "       -0.10428273,  0.62263618,  0.11223299, -0.68919495,  0.09794004,\n",
       "       -0.22340117, -0.7494297 ,  0.42835691,  0.03208361, -0.69267894,\n",
       "        0.76123118, -0.43541277,  0.5674477 , -0.13698194,  0.5746157 ,\n",
       "       -0.42001125, -0.04299159,  0.42217684,  0.16014352,  0.04866797,\n",
       "       -0.57873064, -0.64326056,  0.70801836, -0.21074977, -0.15644703,\n",
       "       -0.29189984, -0.63293028,  0.04780449])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[5999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
