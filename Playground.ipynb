{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython import embed\n",
    "import pandas as pd\n",
    "from word2vec import get_word_embedding\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = 6000\n",
    "\n",
    "# _NUM_UNITS = 128\n",
    "# _NUM_LAYERS = 4\n",
    "# _BATCH_SIZE = 64\n",
    "# _LEARNING_RATE = 0.002\n",
    "# _LEARNING_DECAY_FACTOR = 0.97\n",
    "\n",
    "# BUCKETS = []\n",
    "\n",
    "# model = Seq2SeqModel(\n",
    "#     source_vocab_size=VOCAB_SIZE,\n",
    "#     target_vocab_size=VOCAB_SIZE,\n",
    "#     buckets=BUCKETS,\n",
    "#     size=_NUM_UNITS,\n",
    "#     num_layers=_NUM_LAYERS,\n",
    "#     max_gradient_norm=100,\n",
    "#     batch_size=_BATCH_SIZE,\n",
    "#     learning_rate=_LEARNING_RATE,\n",
    "#     learning_rate_decay_factor=_LEARNING_DECAY_FACTOR,\n",
    "#     use_lstm=False,\n",
    "#     num_samples=512,\n",
    "#     forward_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/vm/qyp8p3y55fj3w0yz7_9pgs9w0000gn/T/jieba.cache\n",
      "Loading model cost 2.962 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_BATCH_SIZE = 64\n",
    "_VOCAB_SIZE = 6000\n",
    "_WORD_DIM = 128\n",
    "\n",
    "_INPUT_LENGTH = 25\n",
    "_OUTPUT_LENGTH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frameworks.seq2seq_keras.models import AttentionSeq2Seq\n",
    "model = AttentionSeq2Seq(input_length=_INPUT_LENGTH, \n",
    "                         input_dim=_WORD_DIM, \n",
    "                         hidden_dim=128, \n",
    "                         output_length=_OUTPUT_LENGTH, \n",
    "                         output_dim=_WORD_DIM, \n",
    "                         depth=4)\n",
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_word_embedding(_WORD_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = get_train_data()\n",
    "_, ch2int = get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39956"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_to(lst, length, value):\n",
    "    for i in range(len(lst), length):\n",
    "        lst.append(value)\n",
    "    \n",
    "    return lst\n",
    "\n",
    "def clean_train_data(train_data):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for idx in xrange(len(train_data)):\n",
    "        line_number = idx % 4\n",
    "        \n",
    "        keyword = train_data[idx]['keyword']\n",
    "        current_sentence = train_data[idx]['sentence']\n",
    "        previous_sentences = ''.join([train_data[idx - i]['sentence'] for i in range(line_number, 0, -1)])\n",
    "        \n",
    "        X_entry = pad_to([[ch2int[ch]] for ch in (keyword + previous_sentences)], 25, [_VOCAB_SIZE - 1])\n",
    "        Y_entry = pad_to([[ch2int[ch]] for ch in current_sentence], 10, [_VOCAB_SIZE - 1])\n",
    "        \n",
    "        X_train.append(X_entry)\n",
    "        Y_train.append(Y_entry)\n",
    "        \n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = clean_train_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embedded = [map(lambda x: embedding[x[0]], sample) for sample in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_embedded = [map(lambda x: embedding[x[0]], sample) for sample in Y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "39956/39956 [==============================] - 1138s - loss: 0.4328  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a49679d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_embedded, Y_train_embedded, epochs=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kw = u'山水'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_pad = [pad_to([[ch2int[ch]] for ch in kw], 25, [_VOCAB_SIZE - 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_embed = [map(lambda x: embedding[x[0]], sample) for sample in kw_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_embed_array = np.array(kw_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.07901192,  0.05590886, -0.18306582, ..., -0.02780079,\n",
       "          0.22095318,  0.06291175],\n",
       "        [-0.08044007,  0.2160262 , -0.211705  , ..., -0.04248908,\n",
       "          0.20641054,  0.20601243],\n",
       "        [-0.12439758,  0.15313667, -0.10564294, ...,  0.0318213 ,\n",
       "          0.1692463 , -0.03528845],\n",
       "        ..., \n",
       "        [-0.03381282, -0.23145901,  0.80336988, ...,  0.77744192,\n",
       "         -0.29983968, -0.52655691],\n",
       "        [-0.04145544, -0.23551586,  0.82956284, ...,  0.80246538,\n",
       "         -0.31093204, -0.54147804],\n",
       "        [-0.03681917, -0.22557406,  0.83075798, ...,  0.80682409,\n",
       "         -0.3058888 , -0.53655243]]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(kw_embed_array)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('data/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(pred[0])):\n",
    "    result.append(w2v_model.most_similar(positive=[pred[0][i]], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "又\n",
      "皈\n",
      "春\n",
      "花\n",
      "送\n",
      "灺\n",
      "情\n",
      "透\n",
      "透\n",
      "透\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print r[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
